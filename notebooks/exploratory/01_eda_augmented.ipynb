{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36cfff3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ROOT: C:\\Users\\MaxGillum\\Desktop\\cmse492_project\n",
      "\n",
      "--- Loading Zillow Data ---\n",
      "\n",
      "--- Calculating Structural Features ---\n",
      "\n",
      "--- Processing Crime Data ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MaxGillum\\AppData\\Local\\Temp\\ipykernel_27696\\2654920871.py:164: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  crimes['date'] = pd.to_datetime(crimes['date'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crime API merged.\n",
      "\n",
      "--- Generating Advanced Features ---\n",
      "Saved. Shape: (7410, 22), Path: C:\\Users\\MaxGillum\\Desktop\\cmse492_project\\data\\processed\\chicago_augmented_12m.csv\n"
     ]
    }
   ],
   "source": [
    "# 01_eda_augmented.ipynb\n",
    "# Build an enriched, synthetic dataset for Chicago ZIP codes:\n",
    "# - Start from Zillow ZORI rent index\n",
    "# - Add structural features (distance to Loop)\n",
    "# - Add crime (API + synthetic fallback)\n",
    "# - Add economic & lifestyle features\n",
    "# - Save as data/processed/chicago_augmented_12m.csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1. PROJECT ROOT + PATHS\n",
    "#    Walk upward until we find data/raw/zori_zip.csv\n",
    "#    This makes the notebook robust no matter where it's run from.\n",
    "# --------------------------------------------------\n",
    "\n",
    "ROOT = Path.cwd().resolve()\n",
    "target = Path(\"data\") / \"raw\" / \"zori_zip.csv\"\n",
    "\n",
    "while not (ROOT / target).exists():\n",
    "    if ROOT == ROOT.parent:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Could not find {target} above cwd={Path.cwd().resolve()}\"\n",
    "        )\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "print(\"Using ROOT:\", ROOT)\n",
    "\n",
    "RAW  = ROOT / \"data\" / \"raw\"\n",
    "PROC = ROOT / \"data\" / \"processed\"\n",
    "PROC.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2. LOAD ZILLOW TARGET (ZORI) AND BUILD RENT ALPHA\n",
    "# --------------------------------------------------\n",
    "\n",
    "print(\"\\n--- Loading Zillow Data ---\")\n",
    "zori_path = RAW / \"zori_zip.csv\"\n",
    "if not zori_path.exists():\n",
    "    raise FileNotFoundError(\"zori_zip.csv missing\")\n",
    "\n",
    "# RegionName = ZIP code\n",
    "zori = pd.read_csv(zori_path, dtype={'RegionName': str})\n",
    "\n",
    "# Keep Illinois only, then Chicago metro only (if Metro column exists)\n",
    "zori = zori[zori['StateName'] == 'IL'].copy()\n",
    "if 'Metro' in zori.columns:\n",
    "    zori = zori[zori['Metro'].str.contains('Chicago', na=False)]\n",
    "\n",
    "# Wide → long: one row per (zip, date)\n",
    "date_cols = [c for c in zori.columns if c[:2] == '20']\n",
    "zori_long = zori.melt(\n",
    "    id_vars=['RegionName', 'City', 'CountyName'],\n",
    "    value_vars=date_cols,\n",
    "    var_name='date',\n",
    "    value_name='rent'\n",
    ")\n",
    "\n",
    "zori_long['date'] = pd.to_datetime(zori_long['date'])\n",
    "zori_long['rent'] = pd.to_numeric(zori_long['rent'], errors='coerce')\n",
    "zori_long = zori_long.rename(columns={'RegionName': 'zip'})\n",
    "zori_long = zori_long.dropna(subset=['rent']).sort_values(['zip', 'date'])\n",
    "\n",
    "# 12-month forward rent growth per ZIP\n",
    "zori_long['zip_12m_growth'] = zori_long.groupby('zip')['rent'].transform(\n",
    "    lambda x: x.shift(-12) / x - 1\n",
    ")\n",
    "\n",
    "# Metro-wide average alpha per month\n",
    "metro_avg = (\n",
    "    zori_long\n",
    "    .groupby('date')['zip_12m_growth']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'zip_12m_growth': 'metro_12m_growth'})\n",
    ")\n",
    "\n",
    "# Relative growth (alpha) = ZIP growth - overall metro growth\n",
    "zori_long = zori_long.merge(metro_avg, on='date', how='left')\n",
    "zori_long['relative_12m_growth'] = (\n",
    "    zori_long['zip_12m_growth'] - zori_long['metro_12m_growth']\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3. STRUCTURAL FEATURES: DISTANCE TO THE LOOP\n",
    "# --------------------------------------------------\n",
    "\n",
    "print(\"\\n--- Calculating Structural Features ---\")\n",
    "zip_geojson = RAW / \"Boundaries_-_ZIP_Codes_20251207.geojson\"\n",
    "\n",
    "if zip_geojson.exists():\n",
    "    gdf_zip = gpd.read_file(zip_geojson)\n",
    "\n",
    "    # Ensure join key matches Zillow ZIP dtype\n",
    "    gdf_zip['zip'] = gdf_zip['zip'].astype(str)\n",
    "\n",
    "    # Approximate Chicago Loop point (lon, lat)\n",
    "    loop_pt = Point(-87.6278, 41.8820)\n",
    "\n",
    "    # Project to local planar CRS (Illinois State Plane) to measure in feet\n",
    "    gdf_zip = gdf_zip.to_crs(epsg=3435)\n",
    "    loop_series = gpd.GeoSeries(\n",
    "        [loop_pt] * len(gdf_zip),\n",
    "        crs=\"EPSG:4326\"\n",
    "    ).to_crs(epsg=3435)\n",
    "\n",
    "    # Distance from each ZIP centroid to Loop, in miles\n",
    "    gdf_zip['dist_to_loop_miles'] = (\n",
    "        gdf_zip.centroid.distance(loop_series) / 5280\n",
    "    )\n",
    "\n",
    "    dist_map = gdf_zip[['zip', 'dist_to_loop_miles']].copy()\n",
    "    zori_long = zori_long.merge(dist_map, on='zip', how='left')\n",
    "\n",
    "    # Conservative fallback for missing shapes\n",
    "    zori_long['dist_to_loop_miles'] = zori_long['dist_to_loop_miles'].fillna(20)\n",
    "else:\n",
    "    # If shapes are missing, assume “far” from Loop (suburban)\n",
    "    zori_long['dist_to_loop_miles'] = 20\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. CRIME DATA: API + FALLBACK\n",
    "# --------------------------------------------------\n",
    "\n",
    "print(\"\\n--- Processing Crime Data ---\")\n",
    "crime_file = RAW / \"chicago_crimes.csv\"\n",
    "\n",
    "# Map community areas (CA) → representative ZIPs\n",
    "ca_to_zip = {\n",
    "    8: '60611', 32: '60601', 24: '60622', 6: '60657', 7: '60614',\n",
    "    22: '60647', 28: '60607', 3: '60640', 4: '60625', 5: '60618'\n",
    "}\n",
    "\n",
    "# Download from City of Chicago API if missing locally\n",
    "if not crime_file.exists():\n",
    "    try:\n",
    "        url = (\n",
    "            \"https://data.cityofchicago.org/resource/ijzp-q8t2.csv\"\n",
    "            \"?$where=date >= '2020-01-01T00:00:00'&$limit=50000\"\n",
    "        )\n",
    "        r = requests.get(url)\n",
    "        with open(crime_file, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "    except Exception:\n",
    "        # If API fails we’ll fall back to synthetic crime later\n",
    "        pass\n",
    "\n",
    "# Try to join crime to ZORI\n",
    "if crime_file.exists():\n",
    "    try:\n",
    "        # Note: original CSV has capitalized column names\n",
    "        crimes = pd.read_csv(\n",
    "            crime_file,\n",
    "            usecols=['Date', 'Primary Type', 'Community Area']\n",
    "        )\n",
    "        crimes.columns = ['date', 'primary_type', 'community_area']\n",
    "\n",
    "        # Monthly aggregation\n",
    "        crimes['date'] = pd.to_datetime(crimes['date'], errors='coerce')\n",
    "        crimes = crimes.dropna(subset=['community_area'])\n",
    "        crimes['community_area'] = crimes['community_area'].astype(int)\n",
    "\n",
    "        crime_agg = (\n",
    "            crimes\n",
    "            .groupby(['community_area', 'date'])\n",
    "            .size()\n",
    "            .reset_index(name='count')\n",
    "        )\n",
    "\n",
    "        # Rolling 12-month sum per community area\n",
    "        crime_agg['crime_12m_sum'] = crime_agg.groupby('community_area')['count'] \\\n",
    "                                              .transform(lambda x: x.rolling(12).sum())\n",
    "\n",
    "        # Map CA → ZIP and then average within each ZIP/date\n",
    "        crime_agg['zip'] = crime_agg['community_area'].map(ca_to_zip)\n",
    "        crime_zip = (\n",
    "            crime_agg\n",
    "            .groupby(['zip', 'date'])['crime_12m_sum']\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "        crime_zip['zip'] = crime_zip['zip'].astype(str)\n",
    "\n",
    "        zori_long = zori_long.merge(\n",
    "            crime_zip,\n",
    "            on=['zip', 'date'],\n",
    "            how='left'\n",
    "        )\n",
    "        print(\"Crime API merged.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Crime merge failed: {e}\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5. ADVANCED ECONOMIC + LIFESTYLE FEATURES\n",
    "# --------------------------------------------------\n",
    "\n",
    "print(\"\\n--- Generating Advanced Features ---\")\n",
    "\n",
    "# ---------- Income ----------\n",
    "# If we don't already have ACS income, synthesize a smooth distribution per ZIP.\n",
    "if 'median_income' not in zori_long.columns:\n",
    "    np.random.seed(42)\n",
    "    unique_zips = zori_long['zip'].unique()\n",
    "\n",
    "    # Uniform on [35k, 120k] to avoid the \"clumping\" problem of small quantile bins\n",
    "    income_levels = np.random.uniform(35000, 120000, len(unique_zips))\n",
    "    zip_income_map = dict(zip(unique_zips, income_levels))\n",
    "    zori_long['median_income'] = zori_long['zip'].map(zip_income_map)\n",
    "else:\n",
    "    unique_zips = zori_long['zip'].unique()\n",
    "    # median_income already present\n",
    "\n",
    "# ---------- Crime fallback ----------\n",
    "# If crime data didn't merge or is all zeros, synthesize an inverse-income signal.\n",
    "if 'crime_12m_sum' not in zori_long.columns or zori_long['crime_12m_sum'].sum() == 0:\n",
    "    inc_norm = (\n",
    "        (zori_long['median_income'] - zori_long['median_income'].min()) /\n",
    "        (zori_long['median_income'].max() - zori_long['median_income'].min())\n",
    "    )\n",
    "    zori_long['crime_12m_sum'] = (\n",
    "        (1 - inc_norm) * 800 + np.random.normal(0, 50, len(zori_long))\n",
    "    )\n",
    "    zori_long['crime_12m_sum'] = zori_long['crime_12m_sum'].clip(lower=0)\n",
    "\n",
    "# Convenience handles\n",
    "dist = zori_long['dist_to_loop_miles']\n",
    "inc = zori_long['median_income']\n",
    "\n",
    "# ---------- Transit score ----------\n",
    "# High in city center, decays with distance, plus a bit of noise\n",
    "zori_long['transit_score'] = (\n",
    "    (100 - dist * 3).clip(10, 100) + np.random.normal(0, 5, len(zori_long))\n",
    ")\n",
    "\n",
    "# ---------- Housing age ----------\n",
    "# Older housing stock near the city, newer in outer suburbs\n",
    "zori_long['housing_age_median'] = (\n",
    "    (100 - dist * 2).clip(10, 90) + np.random.normal(0, 10, len(zori_long))\n",
    ")\n",
    "\n",
    "# ---------- Vacancy rate ----------\n",
    "# U-shaped relationship: higher vacancy at very low and very high income\n",
    "zori_long['vacancy_rate'] = (np.abs(inc - 70000) / 70000) * 0.1 + 0.02\n",
    "\n",
    "# ---------- Poverty rate ----------\n",
    "zori_long['poverty_rate'] = ((150000 - inc) / 150000).clip(0, 0.4)\n",
    "\n",
    "# ---------- University proximity ----------\n",
    "# Mark ~10% of ZIPs as “college-adjacent”\n",
    "np.random.seed(99)\n",
    "college_zips = np.random.choice(\n",
    "    unique_zips,\n",
    "    size=int(len(unique_zips) * 0.1),\n",
    "    replace=False\n",
    ")\n",
    "zori_long['university_flag'] = np.where(\n",
    "    zori_long['zip'].isin(college_zips),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "\n",
    "# ---------- Lifestyle indices ----------\n",
    "if 'hipster_score' not in zori_long.columns:\n",
    "    # Hipster: sweet spot around 4 miles, boosted by income\n",
    "    zori_long['hipster_score'] = (\n",
    "        np.exp(-(dist - 4) ** 2 / 10) * 100 + (inc / 4000)\n",
    "    ).clip(0, 100)\n",
    "\n",
    "    # Nightlife: strongest close to Loop\n",
    "    zori_long['nightlife_index'] = (\n",
    "        np.where(dist < 3, 90, 20) + np.random.normal(0, 5, len(zori_long))\n",
    "    ).clip(0, 100)\n",
    "\n",
    "    # Wellness: driven by income with a little noise\n",
    "    zori_long['wellness_index'] = (\n",
    "        (inc / 1500) + np.random.normal(0, 5, len(zori_long))\n",
    "    ).clip(0, 100)\n",
    "\n",
    "    # Pet-friendliness: best in inner suburbs (3-12 miles out)\n",
    "    zori_long['pet_index'] = (\n",
    "        np.where((dist > 3) & (dist < 12), 80, 40)\n",
    "        + np.random.normal(0, 10, len(zori_long))\n",
    "    ).clip(0, 100)\n",
    "\n",
    "    # School rating: mix of income and distance\n",
    "    zori_long['school_rating'] = (\n",
    "        (inc / 25000) * 0.6 + (dist / 4) * 0.4\n",
    "    ).clip(1, 10)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 6. FINAL CLEANUP + SAVE\n",
    "# --------------------------------------------------\n",
    "\n",
    "# If permits_12m_sum was never generated upstream, create a 0 baseline\n",
    "zori_long['permits_12m_sum'] = zori_long.get(\n",
    "    'permits_12m_sum',\n",
    "    pd.Series(0, index=zori_long.index)\n",
    ").fillna(0)\n",
    "\n",
    "# Keep only rows where we have a valid target, fill remaining NaNs with 0\n",
    "df_model = zori_long.dropna(subset=['relative_12m_growth']).fillna(0)\n",
    "\n",
    "out_path = PROC / \"chicago_augmented_12m.csv\"\n",
    "df_model.to_csv(out_path, index=False)\n",
    "print(f\"Saved. Shape: {df_model.shape}, Path: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b608b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv: cmse492_project)",
   "language": "python",
   "name": "cmse492_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
